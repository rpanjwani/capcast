{"name":"Capcast","tagline":"","body":"# capCast\r\nA video conferencing app that produces speech to text captions in real time. This project will comprise of combined project work for Csc 462/562, Csc 466/566, and Csc 461/561.\r\n\r\n## How to use\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Simple-Walkthrough) contains a simple walkthrough for our webapp.\r\n\r\n## Installation Instructions\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Installation-&-Tools-Instructions) contains instructions on how to get the front-end running on your machine, our coding structure, test cases, etc.\r\n\r\n## Code Structure & Interfaces\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Code-Structure-&-Interfaces) details the code structure & interface.\r\n\r\n## Handling Failures\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Handling-Failures) talks about how we handle failures in our web app.\r\n\r\n## Test Cases\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Test-cases) details the test cases we tried.\r\n\r\n## Log\r\nOur [wiki](https://github.com/rpanjwani/capcast/wiki/Logbook) contains updates on our struggles and endeavours while we build this awesome project.\r\n\r\n## Why?\r\nCapCast will allow video conferencing using a web-browser while producing captions in real time. This can aid in better communication between users in the following ways:\r\n- When there are connection problems at the client end, the video and audio quality may degrade making communication difficult. Having captions can allow the conversation to go on.\r\n- Help people with hearing disabilities.\r\n- Make communication better by simply using more channels (video/audio + caption text).\r\n- Save the transcript so the clients can review it later without having to save the audio/video.\r\n- Users don't have to sign up for accounts. They just have to generate a one-time shareable link for a conversation and distribute it to the parties with whom communication is desired. \r\n\r\n## What else is out there?\r\nThere are other video conferencing services out there like skype, google hangouts, etc. However, we haven't been able to find anything that provides captioning in real time. Also these other services make people sign up for accounts, whereas with our service, users just have to generate a one-time shareable link for a conversation and distribute it to the parties with whom communication is desired. \r\n \r\n## Contributors\r\n- Riz Panjwani\r\n- Harsh Dawar\r\n- Sumit Kadyan\r\n- Khushboo Gandhi\r\n \r\n## Key Features\r\nCapCast will allow a user to do the following:\r\n- generate a link for the video conference that users can share to join the conference.\r\n- call one or more users.\r\n- turn captioning on/off.\r\n- save the caption transcript.\r\n\r\n## Major Components\r\n\r\nWe have broken down the project into the following components that correspond to the appropriate course work below.\r\n\r\n### Peer to Peer Clients (csc 466 / 566 - P2P Overlay Component)\r\nA client is simply a browser running on a user's computer. If the call is one-to-one (only two clients connected to each other), then capCast will use a P2P connection using WebRTC in order to stream the video conference. Otherwise, it will switch to using a capCast host server to carry out the communication.\r\n\r\n### CapCast Host Servers (csc 462 / 562 - Distributed Systems Component)\r\nCapCast host servers will be a distributed system that host the application. The system will facilitate a call between users. If there are two clients, the system will offload the streaming to the p2p model, where the clients will handle the streaming amongst themselves. When a call involves more than two clients, the server will facilitate the video streaming. We will simulate delays, network loss, and node fault to demonstrate the system's ability to cope with failure.\r\n\r\n### Video Streaming and Captioning (csc 461 / 561 - Multimedia Systems Component)\r\nVideo conferencing will be done using HTML5 and WebRTC. Real-time speech to text captioning will be done using the Google Web Speech API.\r\n\r\n## Milestones (2015)\r\n- Feb 16: Have Signal host servers up and running in order to detect peers, setup media ports, etc. in order to establish initial handshake.\r\n- Mar 2: Have p2p streaming setup and working along with captioning and transcripting (on client side).\r\n- Mar 16: Facilitate multi-party video streaming using the host servers along with captioning and transcripting(on server side).\r\n- Mar 23: Produce a finalized system including performance benchmarks, testing, tweaks, ui-polishing, etc.\r\n\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}